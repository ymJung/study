import os
import fitz  # PyMuPDF

from pptx import Presentation # ppt
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Milvus
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA

from pymilvus import connections
import configparser

config = configparser.ConfigParser()
config.read('config.cfg')
openai_api_key = config['openai']['TOKEN']
VECTOR_HOST = "localhost"
VECTOR_PORT = "19530"

# 1. ë¬¸ì„œ ì „ì²˜ë¦¬,  ì²­í‚¹
"""
PDF -> text docs
    Chunking -> LangChain ( RecursiveCharacterTextSplitter )
        ADD metadata - {text, source, page} 
"""
def process_pdf(file_path):
 
    docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    
    with fitz.open(file_path) as pdf:
        for page in pdf:
            # í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = page.get_text("text").strip()
            # ì²­í‚¹: í˜ì´ì§€ ë‚´ í…ìŠ¤íŠ¸ë¥¼ chunk_size 500, overlap 100ë¡œ ë¶„í• 
            chunks = splitter.split_text(text)
            for chunk in chunks:
                metadata = {"source": os.path.basename(file_path), "page": page.number + 1}
                docs.append(Document(page_content=chunk, metadata=metadata))
    return docs

"""
PPT -> text docs
    Chunking -> pptx ( Presentation )  text, shape.text
        ADD metadata {text, source, slide} 
"""
def process_ppt(file_path):
    docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    prs = Presentation(file_path)
    
    for i, slide in enumerate(prs.slides):
        slide_text = ""
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text:
                slide_text += shape.text + "\n"
        if slide.has_notes_slide:
            notes_slide = slide.notes_slide
            for shape in notes_slide.shapes:
                if hasattr(shape, "text") and shape.text:
                    slide_text += shape.text + "\n"
        if slide_text.strip():
            chunks = splitter.split_text(slide_text)
            for chunk in chunks:
                metadata = {"source": os.path.basename(file_path), "slide": i + 1}
                docs.append(Document(page_content=chunk, metadata=metadata))
    return docs

"""
vector db ì— ì—°ê²°í•˜ê³ , HuggingFaceEmbeddings("all-mpnet-base-v2")ë¥¼ ì‚¬ìš©í•˜ì—¬
ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì„ë² ë”©í•œ í›„ Milvusì— ì €ì¥í•˜ì—¬ vectorstore ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
"""
def setup_vector_store(documents):
    # Milvus ì„œë²„ì— ì—°ê²° (ê¸°ë³¸: localhost:19530)
    connections.connect(alias="default", host=VECTOR_HOST, port=VECTOR_PORT)
    embeddings = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
    vectorstore = Milvus.from_documents(documents, embeddings, collection_name="document_collection")
    return vectorstore

"""
vectorstoreì™€ LLM(ê¸°ë³¸: OpenAIì˜ GPT-4)ì„ ì´ìš©í•˜ì—¬ LangChainì˜ RetrievalQA ì²´ì¸ì„ ìƒì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
LLMì„ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ êµì²´í•˜ë ¤ë©´ llm ë§¤ê°œë³€ìˆ˜ì— ì»¤ìŠ¤í…€ LLM ê°ì²´ë¥¼ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤.
"""
def create_retrieval_qa(vectorstore, llm=None): 
    if llm is None:
        llm = OpenAI(model_name="gpt-4", temperature=0)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )
    return qa


"""
ì‚¬ìš©ìë¡œë¶€í„° ì§ˆì˜ë¥¼ ì…ë ¥ë°›ì•„ RetrievalQA ì²´ì¸ì„ í†µí•´ ë‹µë³€ì„ ìƒì„±í•˜ê³ ,
ì‘ë‹µ ê²°ê³¼ì™€ í•¨ê»˜ ê° ì²­í¬ì˜ ì¶œì²˜(íŒŒì¼ëª… ë° í˜ì´ì§€/ìŠ¬ë¼ì´ë“œ ë²ˆí˜¸)ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
"""
def query_loop(qa):
    print("ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    while True:
        query = input("\nğŸ”¹ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if query.lower().strip() == "exit":
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        result = qa({"query": query})
        answer = result.get("result", "")
        source_docs = result.get("source_documents", [])

        # ê´€ë ¨ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ì‘ë‹µ ì²˜ë¦¬
        if not source_docs:
            answer = "í•´ë‹¹ ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤."
            source_str = "General Agent"
        else:
            sources = []
            for doc in source_docs:
                meta = doc.metadata
                if "page" in meta:
                    sources.append(f"{meta['source']} {meta['page']}í˜ì´ì§€")
                elif "slide" in meta:
                    sources.append(f"{meta['source']} {meta['slide']}ìŠ¬ë¼ì´ë“œ")
            source_str = ", ".join(sources)
        
        print("ë‹µë³€:", answer)
        print("ì¶œì²˜:", source_str)




def main():
    # 1) PDF, PPT ë¬¸ì„œ ì²˜ë¦¬
    documents = [process_pdf(".pdf"), process_pdf(".pdf")]  
    # 2) VECTOR ì €ì¥
    vectorstore = setup_vector_store(documents)
    # 3) RAG ìƒì„±
    qa = create_retrieval_qa(vectorstore)
    # 4) ì§ˆì˜ ì‹¤í–‰
    query_loop(qa)

if __name__ == '__main__':
    main()

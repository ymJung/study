import os
import fitz  # pip install PyMuPDF
from pptx import Presentation  # pip install python-pptx
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

from langchain_huggingface import HuggingFaceEmbeddings

from langchain_community.vectorstores import Qdrant
from langchain_community.chat_models import ChatOpenAI

from langchain.chains import RetrievalQA
import configparser

# ì„¤ì • íŒŒì¼ ë¡œë“œ
config = configparser.ConfigParser()
config.read('config.cfg')
openai_api_key = config['openai']['TOKEN']

# vector db
QDRANT_URL = "http://localhost:6333"

"""
PDF -> í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    - ì²­í‚¹(Chunking): RecursiveCharacterTextSplitter í™œìš©
    - ë©”íƒ€ë°ì´í„° ì¶”ê°€: {source, page}
"""
def process_pdf(file_path):
    docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    
    with fitz.open(file_path) as pdf:
        for page in pdf:
            text = page.get_text("text").strip()
            chunks = splitter.split_text(text)
            for chunk in chunks:
                metadata = {"source": os.path.basename(file_path), "page": page.number + 1}
                docs.append(Document(page_content=chunk, metadata=metadata))
    return docs

"""
PPT -> í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
    - ì²­í‚¹: ìŠ¬ë¼ì´ë“œ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• 
    - ë©”íƒ€ë°ì´í„° ì¶”ê°€: {source, slide}
"""
def process_ppt(file_path):
    docs = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    prs = Presentation(file_path)
    
    for i, slide in enumerate(prs.slides):
        slide_text = ""
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text:
                slide_text += shape.text + "\n"
        if slide.has_notes_slide:
            notes_slide = slide.notes_slide
            for shape in notes_slide.shapes:
                if hasattr(shape, "text") and shape.text:
                    slide_text += shape.text + "\n"
        if slide_text.strip():
            chunks = splitter.split_text(slide_text)
            for chunk in chunks:
                metadata = {"source": os.path.basename(file_path), "slide": i + 1}
                docs.append(Document(page_content=chunk, metadata=metadata))
    return docs

"""
Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œ ì €ì¥
    - HuggingFaceEmbeddings("all-mpnet-base-v2") í™œìš©
"""
def setup_vector_store(documents):
    # process_pdfë‚˜ process_pptì€ ê°ê° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ì „ì²´ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.
    all_docs = []
    for doc_list in documents:
        all_docs.extend(doc_list)
        
    embeddings = HuggingFaceEmbeddings(model_name="all-mpnet-base-v2")
    vectorstore = Qdrant.from_documents(
        all_docs,
        embeddings,
        collection_name="document_collection",
        url=QDRANT_URL
    )
    return vectorstore

"""
RAG ì²´ì¸ ìƒì„± (ë²¡í„° DB + LLM)
"""
def create_retrieval_qa(vectorstore, llm=None): 
    if llm is None:
        # ChatOpenAIë¥¼ ì‚¬ìš©í•˜ë©° openai_api_keyë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
        llm = ChatOpenAI(model_name="gpt-4", temperature=0, openai_api_key=openai_api_key)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )
    return qa

"""
ì‚¬ìš©ì ì§ˆì˜ì‘ë‹µ ë£¨í”„
    - ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œì™€ ë‹µë³€ì„ ì¶œë ¥.
"""
def query_loop(qa):
    print("ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")
    while True:
        query = input("\nğŸ”¹ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if query.lower().strip() == "exit":
            print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        result = qa({"query": query})
        answer = result.get("result", "")
        source_docs = result.get("source_documents", [])

        source_str = "General Agent"
        if "ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤" in answer or not source_docs: # ë‹µë³€ì´ ì—†ê±°ë‚˜, ê´€ë ¨ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš°
            answer = "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."        
            
        else:
            sources = set()
            for doc in source_docs:
                meta = doc.metadata
                if "page" in meta:
                    sources.add(f"{meta['source']} {meta['page']}í˜ì´ì§€")
                elif "slide" in meta:
                    sources.add(f"{meta['source']} {meta['slide']}ìŠ¬ë¼ì´ë“œ")
            source_str = ", ".join(sources)
        if "ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤" in answer:
            answer = "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        print("ë‹µë³€:", answer)
        print("ì¶œì²˜:", source_str)

def main():
    # PDF ë° PPT ë¬¸ì„œ ì²˜ë¦¬ (ì˜ˆì‹œë¡œ ë‘ ê°œì˜ PDF íŒŒì¼ ì‚¬ìš©)
    documents = [process_pdf(".pdf"), process_pdf(".pdf")]
    # ë²¡í„° DB (Qdrant)ì— ì €ì¥
    vectorstore = setup_vector_store(documents)
    # RAG ì²´ì¸ ìƒì„±
    qa = create_retrieval_qa(vectorstore)
    # ì§ˆì˜ì‘ë‹µ ë£¨í”„ ì‹¤í–‰
    query_loop(qa)

if __name__ == '__main__':
    main()
